{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Download html of particular page of website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the html of page from a valid url, we will use the module urlopen from urllib.request. Python must be told to import this module before it can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list variables here:\n",
    "\n",
    "\n",
    "\n",
    "#modify the url here:\n",
    "url=\"https://www.nytimes.com\";\n",
    "html=urlopen(url)\n",
    "#This next section navigates through the html and prints the date to help verify\n",
    "#the variable string replacement was successful. We'll get into using BeautifulSoup in the next section!\n",
    "#Fow now, just treat it asa a black box\n",
    "from bs4 import BeautifulSoup #black box\n",
    "soup=BeautifulSoup(html.read(),'html.parser') #black box\n",
    "#print(soup.find('h2',class_='history-date').contents) #black box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 19, 17, 45, 57, 979197)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "x=0;\n",
    "while True:\n",
    "    print(x)\n",
    "    url=\"https://www.nytimes.com\";\n",
    "    html=urlopen(url).read()\n",
    "    t=strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    t=t.replace(\"-\",\"\").replace(\" \",\"\").replace(\":\",\"\")\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/nytimes_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    url=\"https://www.foxnews.com\";\n",
    "    html=urlopen(url).read()\n",
    "    time.sleep(1)\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/fox_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    url=\"https://www.washingtonpost.com\";\n",
    "    html=urlopen(url).read()\n",
    "    time.sleep(1)\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/post_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    url=\"http://www.cnn.com/\";\n",
    "    html=urlopen(url).read()\n",
    "    time.sleep(1)\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/cnn_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    url=\"http://www.breitbart.com/\";\n",
    "    html=urlopen(url).read()\n",
    "    time.sleep(1)\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/breitbart_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    url=\"http://www.npr.org\"\n",
    "    html=urlopen(url).read()\n",
    "    time.sleep(1)\n",
    "    with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/npr_%s.html\"%(t), \"w\") as file:\n",
    "        file.write(str(html))\n",
    "    time.sleep(60*60)\n",
    "    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "#import urllib2\n",
    "#import urllib\n",
    "\n",
    "html = urlopen(url).read()\n",
    "with open(\"C:/Users/Kyle/Documents/Blog Posts/Shutdown2018/%s_%s.html\"%(url,t), \"w\") as file:\n",
    "    file.write(str(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the downloaded html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous code block, the html of the downloaded was navigated using BeautifulSoup, a python module designed to make getting to the sections of html you care about easier. In that case, the html was read into BeautifulSoup which allowed me to navigate straight to the html section that was type='h2', class='history-date'. This section guides you to finding the section of the html where the temperature data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's get the html into BeautifulSoup and just ask it to print out everything that's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html=urlopen(url);\n",
    "soup=BeautifulSoup(html.read(),'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've never seen the html of a webpage before, this can look quite intimidating. Learning all about html is outside the scope of this project. For now, just note that every html feature on the webpage has some sort of label, which BeautifulSoup can use to locate.\n",
    "\n",
    "Instead of looking through this html for what you want, it's often much easier to open the page in a browser and 'inspect element' to see the underlaying html code.\n",
    "\n",
    "At least on my computer, that's just a rightclick->inspect element on the feature I want the html tag infomation for.\n",
    "\n",
    "You should try this yourself. First find the html for the bold date and make sure it is the same as in the black box code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the write tags to get the actual mean temperature on Feb. 8th, 2014. (you should get \"['31']\")\n",
    "\n",
    "Example from black box above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write your terms in here\n",
    "print(soup.find('',class_='').contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So are we in the clear? Almost, but try looking up the tags for the average mean temperature. They probably look the same as for the actual mean temperature.\n",
    "\n",
    "While each object in the html has tags, they are not all unique. We can see this by using find_all instead of find.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"city-nav-header is-parent\">\n",
      "\t\tAlvadore, OR\n",
      "\t\t<i class=\"fi-star favorite-star \" data-zmw=\"97409.4.99999\"></i>\n",
      "<dfn class=\"no-decoration\" data-definition=\"Add/Remove home city location.\">\n",
      "<i class=\"fi-home homecity-button notHomepage\" onclick=\"wui.favorites.home.toggle('97409.4.99999', this, 'isHomepage', 'notHomepage', 'Mahlon Sweet, OR');return false;\"></i>\n",
      "</dfn>\n",
      "<i class=\"fi-list favorite-menu right-off-canvas-toggle none\"></i>\n",
      "</h2>, <h2 class=\"history-date\">Saturday, February 8, 2014</h2>, <h2>Daily Weather History Graph</h2>, <h2>\n",
      "\t\tHourly Weather History &amp; Observations\n",
      "\t\t</h2>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('h2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same with the tags used to get the temperature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(soup.find_all('',class_=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were successful, we have all the data we want. The first 8 entries are the various temperature records. We just need to peel them away and save them somewhere locally.\n",
    "\n",
    "Of course, this all goes wrong if every page isn't exactly like this page. We could be fancier and build in some checks, etc. But we won't worry about that here.\n",
    "\n",
    "However, if you'd like to get a bit more information from that table, here's an example code to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td class=\"indent\"><span>Mean Temperature</span></td>\n",
      "\n",
      "\n",
      "<td>\n",
      "<span class=\"wx-data\"><span class=\"wx-value\">31</span><span class=\"wx-unit\"> °F</span></span>\n",
      "</td>\n",
      "['31']\n",
      "\n",
      "\n",
      "<td>\n",
      "<span class=\"wx-data\"><span class=\"wx-value\">42</span><span class=\"wx-unit\"> °F</span></span>\n",
      "</td>\n",
      "['42']\n",
      "\n",
      "\n",
      "<td> </td>\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#All the historical data is in a table in the html (inspect element around the browser to see this).\n",
    "#I start by only looking at the table\n",
    "soup2=soup.find('table', class_='responsive airport-history-summary-table');\n",
    "#each row of the table has it's only class \"indent\", so I find all of those:\n",
    "classSet=soup2.find_all(class_='indent');\n",
    "#I then can go to a particular row and print out all values within that row\n",
    "a=classSet[0] #change here to go to a different row\n",
    "print(a)\n",
    "#Each sibling group only has size 8. I let the range run to 10 to show how break is used in the if statment.\n",
    "for x in range(0,10):\n",
    "    a=a.next_sibling\n",
    "    print(a)\n",
    "    if 'wx-value' in str(a):\n",
    "        b=a.find(class_='wx-value')\n",
    "        print(b.contents)\n",
    "    if a==None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we need to save it somewhere locally. To do that we will use the python module pandas, which is very useful for creating dataframes (think excel tables).\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Col1 Col2 Col3 Col4\n",
       "0    A    b    c    d"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(columns=['Col1','Col2','Col3','Col4']);\n",
    "df.loc[0,'Col1']='A' #appending the date using the .loc method to make use of the column name\n",
    "vals=['b','c','d']\n",
    "df.iloc[0,1:]=vals #appending the temperature data using the .iloc method to make use of column locations\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas dataframe with 9 columns. The first should be for the date the data came from. The remaining 8 should be for the various temperature values given on the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to add the values.\n",
    "\n",
    "First, save the date information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.loc[0,'']=soup.find('',class_='').contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the temperature date, I suggest using a for loop to go through the first 8 returns from the find_all code above.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31']\n",
      "['42']\n",
      "['32']\n",
      "['50']\n",
      "['67']\n",
      "['29']\n",
      "['35']\n",
      "['8']\n"
     ]
    }
   ],
   "source": [
    "tableData=soup.find_all('span',class_='wx-value')\n",
    "for x in range(0,8):\n",
    "    print(tableData[x].contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Saturday, February 8, 2014]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[42]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[67]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date     1     2     3     4     5     6     7    8\n",
       "0  [Saturday, February 8, 2014]  [31]  [42]  [32]  [50]  [67]  [29]  [35]  [8]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short section, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the above steps for many pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to repeat this process for many different dates. \n",
    "\n",
    "Recall from section 1 that we used variable string replacement to control which url we were opening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saturday, February 8, 2014']\n"
     ]
    }
   ],
   "source": [
    "year='2014';\n",
    "month='02';\n",
    "day='08';\n",
    "#modify the url here:\n",
    "url=\"https://www.wunderground.com/history/airport/KEUG/%s/%s/%s/DailyHistory.htmlreq_city=Eugene&req_state=OR&req_statename=Oregon&reqdb.zip=97404&reqdb.magic=1&reqdb.wmo=99999\" % (year, month, day);\n",
    "html=urlopen(url)\n",
    "#This next section navigates through the html and prints the date to help verify\n",
    "#the variable string replacement was successful. We'll get into using BeautifulSoup in the next section!\n",
    "#Fow now, just treat it asa a black box\n",
    "from bs4 import BeautifulSoup #black box\n",
    "soup=BeautifulSoup(html.read(),'html.parser') #black box\n",
    "print(soup.find('h2',class_='history-date').contents) #black box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want a way to automatically go through many dates. We can use the python module datetime to easily move through dates:\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-05\n",
      "2014-02-08\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.date.today())\n",
    "print(datetime.date(2014,2,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What makes datetime nice is it allows for basic addition and subtraction of days.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-05\n",
      "2017-01-04\n",
      "2016-12-29\n"
     ]
    }
   ],
   "source": [
    "one_day = datetime.timedelta(days=1);\n",
    "one_week= datetime.timedelta(days=7);\n",
    "print(datetime.date.today())\n",
    "print(datetime.date.today()-one_day)\n",
    "print(datetime.date.today()-one_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only tricky thing is you have to ask for the datetime to give you the values of the date if you want them for another application.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-05\n",
      "<class 'datetime.date'>\n",
      "2017 01 05\n",
      "<class 'str'>\n",
      "2017\n",
      "01\n",
      "05\n"
     ]
    }
   ],
   "source": [
    "date1=datetime.date.today()\n",
    "print(date1)\n",
    "print(type(date1))\n",
    "date2=date1.strftime('%Y %m %d') #Asking for the values in a string. %Y gives 4 digit year. %y gives 2 digit year.\n",
    "print(date2)\n",
    "print(type(date2))\n",
    "date3=date2.split(' ')\n",
    "yr,mo,da=date3\n",
    "print(yr)\n",
    "print(mo)\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use date time to get the right numbers to put into the url for the weather on  Feb. 5th, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wednesday, February 5, 2014']\n"
     ]
    }
   ],
   "source": [
    "#use datetime to fill in the variables year, month, and day:\n",
    "year,month,day=\n",
    "\n",
    "url=\"https://www.wunderground.com/history/airport/KEUG/%s/%s/%s/DailyHistory.htmlreq_city=Eugene&req_state=OR&req_statename=Oregon&reqdb.zip=97404&reqdb.magic=1&reqdb.wmo=99999\" % (year, month, day);\n",
    "html=urlopen(url)\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(html.read(),'html.parser')\n",
    "print(soup.find('h2',class_='history-date').contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a loop to visit the days from Feb. 5th, 2014 to Feb. 13, 2014.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-05\n",
      "2017-01-04\n",
      "2017-01-03\n",
      "2017-01-02\n",
      "2017-01-01\n",
      "2016-12-31\n",
      "2016-12-30\n"
     ]
    }
   ],
   "source": [
    "startingDay=datetime.date.today()\n",
    "one_day=datetime.timedelta(days=1);\n",
    "for x in range(0,7):\n",
    "    print(startingDay)\n",
    "    startingDay=startingDay-one_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#choose a starting date with datetime here:\n",
    "startingDay=\n",
    "#define the number of days we will go through with each step here:\n",
    "one_day = \n",
    "#write the loop here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine it all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time has finally come to combine everything to make a viable webscraper. Write a webscraper to collect the last 30 days of temperature values.\n",
    "\n",
    "A few hints: \n",
    "\n",
    "    1) create your dataframe at the beginning, before you enter your for loop.\n",
    "    \n",
    "    2) If you have nested for loops, make sure they don't have the same variable.\n",
    "    \n",
    "    3) To test, run your for loop just a few times instead of over the entire range.\n",
    "    \n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thursday, January 5, 2017]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[67]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Wednesday, January 4, 2017]</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[69]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Tuesday, January 3, 2017]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[60]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Monday, January 2, 2017]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[37]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[57]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Sunday, January 1, 2017]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[61]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Saturday, December 31, 2016]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Friday, December 30, 2016]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Thursday, December 29, 2016]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[63]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Wednesday, December 28, 2016]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[41]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[65]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Tuesday, December 27, 2016]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[61]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Monday, December 26, 2016]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Sunday, December 25, 2016]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Saturday, December 24, 2016]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[60]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[-4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Friday, December 23, 2016]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Thursday, December 22, 2016]</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Wednesday, December 21, 2016]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Tuesday, December 20, 2016]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[51]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Monday, December 19, 2016]</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Sunday, December 18, 2016]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Saturday, December 17, 2016]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[68]</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[Friday, December 16, 2016]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[61]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0.00]</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[1.58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[Thursday, December 15, 2016]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[65]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0.00]</td>\n",
       "      <td>[0.25]</td>\n",
       "      <td>[3.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[Wednesday, December 14, 2016]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[60]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[Tuesday, December 13, 2016]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[Monday, December 12, 2016]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[48]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[65]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[Sunday, December 11, 2016]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[42]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[Saturday, December 10, 2016]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>[41]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[Friday, December 9, 2016]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[49]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[67]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[Thursday, December 8, 2016]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[Wednesday, December 7, 2016]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[46]</td>\n",
       "      <td>[67]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[-7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Date     1     2     3     4     5       6  \\\n",
       "0      [Thursday, January 5, 2017]  [24]  [40]  [33]  [46]  [67]    [15]   \n",
       "1     [Wednesday, January 4, 2017]  [28]  [40]  [33]  [46]  [69]    [21]   \n",
       "2       [Tuesday, January 3, 2017]  [30]  [40]  [35]  [46]  [60]    [25]   \n",
       "3        [Monday, January 2, 2017]  [34]  [40]  [37]  [46]  [57]    [30]   \n",
       "4        [Sunday, January 1, 2017]  [36]  [39]  [39]  [45]  [61]    [34]   \n",
       "5    [Saturday, December 31, 2016]  [33]  [39]  [36]  [45]  [62]    [29]   \n",
       "6      [Friday, December 30, 2016]  [39]  [39]  [47]  [45]  [66]    [31]   \n",
       "7    [Thursday, December 29, 2016]  [43]  [39]  [53]  [45]  [63]    [33]   \n",
       "8   [Wednesday, December 28, 2016]  [36]  [39]  [41]  [45]  [65]    [30]   \n",
       "9     [Tuesday, December 27, 2016]  [44]  [39]  [47]  [45]  [61]    [40]   \n",
       "10     [Monday, December 26, 2016]  [33]  [39]  [43]  [45]  [62]    [23]   \n",
       "11     [Sunday, December 25, 2016]  [35]  [39]  [44]  [45]  [62]    [25]   \n",
       "12   [Saturday, December 24, 2016]  [35]  [39]  [44]  [45]  [60]    [26]   \n",
       "13     [Friday, December 23, 2016]  [40]  [39]  [45]  [45]  [66]    [35]   \n",
       "14   [Thursday, December 22, 2016]  [38]  [39]  [45]  [45]  [62]    [30]   \n",
       "15  [Wednesday, December 21, 2016]  [31]  [39]  [33]  [45]  [62]    [29]   \n",
       "16    [Tuesday, December 20, 2016]  [40]  [39]  [51]  [45]  [64]    [28]   \n",
       "17     [Monday, December 19, 2016]  [38]  [39]  [45]  [45]  [64]    [30]   \n",
       "18     [Sunday, December 18, 2016]  [29]  [39]  [31]  [45]  [64]    [26]   \n",
       "19   [Saturday, December 17, 2016]  [31]  [39]  [34]  [45]  [68]    [28]   \n",
       "20     [Friday, December 16, 2016]  [39]  [45]  [61]  [34]  [10]  [0.00]   \n",
       "21   [Thursday, December 15, 2016]  [39]  [45]  [65]  [34]  [10]  [0.00]   \n",
       "22  [Wednesday, December 14, 2016]  [32]  [39]  [34]  [45]  [60]    [30]   \n",
       "23    [Tuesday, December 13, 2016]  [34]  [40]  [38]  [45]  [64]    [30]   \n",
       "24     [Monday, December 12, 2016]  [39]  [40]  [48]  [46]  [65]    [29]   \n",
       "25     [Sunday, December 11, 2016]  [45]  [40]  [47]  [46]  [62]    [42]   \n",
       "26   [Saturday, December 10, 2016]  [46]  [40]  [50]  [46]  [64]    [41]   \n",
       "27      [Friday, December 9, 2016]  [43]  [40]  [49]  [46]  [67]    [36]   \n",
       "28    [Thursday, December 8, 2016]  [32]  [40]  [36]  [46]  [62]    [28]   \n",
       "29   [Wednesday, December 7, 2016]  [31]  [40]  [35]  [46]  [67]    [27]   \n",
       "\n",
       "         7       8  \n",
       "0     [34]    [15]  \n",
       "1     [34]    [14]  \n",
       "2     [34]     [9]  \n",
       "3     [34]     [8]  \n",
       "4     [34]     [7]  \n",
       "5     [34]    [10]  \n",
       "6     [33]    [10]  \n",
       "7     [33]    [12]  \n",
       "8     [33]    [19]  \n",
       "9     [33]    [16]  \n",
       "10    [33]     [1]  \n",
       "11    [33]    [-1]  \n",
       "12    [33]    [-4]  \n",
       "13    [33]    [-2]  \n",
       "14    [33]     [4]  \n",
       "15    [33]     [6]  \n",
       "16    [33]     [7]  \n",
       "17    [33]     [4]  \n",
       "18    [33]     [2]  \n",
       "19    [33]    [10]  \n",
       "20  [0.25]  [1.58]  \n",
       "21  [0.25]  [3.02]  \n",
       "22    [34]    [-2]  \n",
       "23    [34]    [-3]  \n",
       "24    [34]     [4]  \n",
       "25    [34]    [-5]  \n",
       "26    [34]    [-7]  \n",
       "27    [34]    [-5]  \n",
       "28    [34]   [-12]  \n",
       "29    [34]    [-7]  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras:\n",
    "\n",
    "If you have time, you can clean up your saved data. You might have noticed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saturday, February 8, 2014']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2',class_='history-date').contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1900, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime('Saturday','%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1900, 2, 1, 0, 0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime('February','%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 2, 8, 0, 0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime('Saturday February 8 2014', '%A %B %d %Y')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
